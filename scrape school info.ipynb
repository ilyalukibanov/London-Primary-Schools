{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410cf168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read scraped school list\n",
    "school_data = pd.read_csv('data/all_schools.csv')\n",
    "school_links = school_data['link'].tolist()\n",
    "PREFIX = 'https://reports.ofsted.gov.uk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a4a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5159f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for school_link in school_links:\n",
    "    driver.get(f'{PREFIX}{school_link}')\n",
    "    page_html = driver.page_source\n",
    "    page = BeautifulSoup(page_html, 'html.parser')\n",
    "    school_link_split = school_link.split('/')\n",
    "    school_id = school_link_split[-2] + '_' + school_link_split[-1]\n",
    "    \n",
    "    try:\n",
    "        # Last inspection info scraping\n",
    "        ratings = [school_id]\n",
    "        column_names = ['school_id']\n",
    "        # If the school has subjudgements\n",
    "        if len(page.find_all('div', class_='subjudgements__overall')) > 0:\n",
    "            column_names.extend(['overall_info','overall_judgement'])\n",
    "            ratings.append(page.find('div', class_='subjudgements__overall').find('p').get_text().strip())\n",
    "            ratings.append(page.find('div', class_='subjudgements__overall').find('strong').get_text().strip())\n",
    "            subjudgements = []\n",
    "            # Subjudgements might differ between schools, so collect all in unordered fashion\n",
    "            for subjudgement in page.find_all('div', class_='subjudgements__rates__item'):\n",
    "                subjudgements.append([subjudgement.find('p').get_text().strip(),subjudgement.find('strong').get_text().strip()])\n",
    "            subjudgements.sort()\n",
    "            for judgement in subjudgements:\n",
    "                column_names.append(judgement[0])\n",
    "                ratings.append(judgement[1])\n",
    "        # If the school has only the overall judgement\n",
    "        elif len(page.find_all('ol', class_='rating-scale')) > 0:\n",
    "            ratings.append(True)\n",
    "            ratings.append(page.find('li', class_='rating--selected').find('span').get_text().strip())\n",
    "            column_names.extend(['is_short_overall','overall_judgement'])\n",
    "        ratings = pd.DataFrame([ratings], columns=column_names)\n",
    "        ratings.to_csv(f'data/ratings/{school_id}.csv',index=False)\n",
    "\n",
    "        # Inspection data scraping\n",
    "        inspections = page.find_all('ol', class_='timeline')[0].find_all('div', class_='event')\n",
    "        inspections_list = []\n",
    "        for inspection in inspections[:]:\n",
    "            # Check that it is not one of initial entries (open/registration/etc)\n",
    "            # Those entries do not contain any useful information, so skip them\n",
    "            record_detail = inspection.find_all('span', class_='event__title')[0].get_text().lower()\n",
    "            if not (record_detail in ('opened', 'proposed to open', 'registration') \n",
    "                    or 'previously' in record_detail\n",
    "                    or 'converted' in record_detail):\n",
    "                inspection_data = []\n",
    "                # Inspection/record date\n",
    "                inspection_data.append(inspection.find_all('time')[0].get_text().strip())\n",
    "                entry = inspection.find_all('a', href=True)[0]\n",
    "                # Link to the inspection pdf file\n",
    "                inspection_data.append(entry['href'])\n",
    "                # Inspection details\n",
    "                inspection_data.append(BeautifulSoup(str(re.sub(\"\"\"<span class=\"nonvisual\">.*</span>\"\"\", '', str(entry))), 'html.parser').get_text().strip())\n",
    "                # Inspection publication date\n",
    "                inspection_data.append(inspection.find_all('time')[1].get_text().strip())\n",
    "                inspections_list.append(inspection_data)\n",
    "        school_inspection_data = pd.DataFrame(inspections_list, columns=['record_date','link','record_details','publication_date'])\n",
    "        school_inspection_data['school_id'] = school_id\n",
    "        school_inspection_data.to_csv(f'data/inspections/{school_id}.csv',index=False)\n",
    "    # Catch schools with unexpected structure\n",
    "    # Save their ids for future investigation \n",
    "    except:\n",
    "        with open(f'data/exceptions/{school_id}.txt', 'w') as file:\n",
    "            file.write(school_id)\n",
    "    time.sleep(random.uniform(5,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821681d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for file in os.listdir('data/inspections/'):\n",
    "    files.append(pd.read_csv(f'data/inspections/{file}'))\n",
    "inspection_data = pd.concat(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ac369",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspection_data.to_csv('data/inspection_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb889c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for file in os.listdir('data/ratings/'):\n",
    "    files.append(pd.read_csv(f'data/ratings/{file}'))\n",
    "rating_data = pd.concat(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14cab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data.to_csv('data/rating_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
