{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd77d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc59c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c78f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Districts are from: https://www.doogal.co.uk/london_postcodes\n",
    "districts = [f'EC{i}{l}' for i in range(1,5) for l in ('A','M','N','P','R','V')]\\\n",
    "    + [f'EC{i}Y' for i in (1,2,4)]\\\n",
    "    + [f'WC{i}{l}' for i in (1,2) for l in ('A','B','E','H','N','R')]\\\n",
    "    + ['WC1V','WC1X','E20']\\\n",
    "    + [f'{l}{i}' for m,l in [(19,'E'),(23,'N'),(12,'NW'),(29,'SE'),(21,'SW'),(15,'W')] for i in range(1,m)]\n",
    "print(f'Number of districts: {len(districts)}')\n",
    "print('District list:', districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea707f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_schools(\n",
    "    url : str,\n",
    "    save_folder : str\n",
    ") -> None:\n",
    "    for district in districts:\n",
    "        driver.get(url.format(district))\n",
    "        not_finished = True\n",
    "        time.sleep(random.uniform(5,8))\n",
    "        # Finish when 1) the page shows any other district schools or 2) when reached the last page \n",
    "        while not_finished:\n",
    "            page_html = driver.page_source\n",
    "            # Parse page HTML\n",
    "            page = BeautifulSoup(page_html, 'html.parser')\n",
    "            schools = page.find_all('ul', class_='results-list')[0]\n",
    "            schools_list = []\n",
    "            for school in schools.find_all('li', class_='search-result'):\n",
    "                school_info = []\n",
    "                s = school.find('h3').find('a')\n",
    "                # School name\n",
    "                school_info.append(s.get_text().strip())\n",
    "                # School link\n",
    "                school_info.append(s['href'])\n",
    "                # School address\n",
    "                school_info.append(school.find('address').get_text().strip())\n",
    "                sub_info = school.find_all('ul')\n",
    "                # School category\n",
    "                school_info.append(sub_info[0].find('strong').get_text().strip())\n",
    "                metric_type = sub_info[1].get_text().split(':')[0]\n",
    "                # Newly registered schools don't have any further info\n",
    "                if 'a newly registered school' in metric_type:\n",
    "                    school_info.append('')\n",
    "                    school_info.append('')\n",
    "                else:\n",
    "                    # School last inspection score\n",
    "                    if metric_type == 'Rating':\n",
    "                        school_info.append(sub_info[1].find('strong').get_text().strip())\n",
    "                        report_index = 2\n",
    "                    # Some schools are not rated yet\n",
    "                    else:\n",
    "                        school_info.append('')\n",
    "                        report_index = 1\n",
    "                    # School last report date\n",
    "                    school_info.append(sub_info[report_index].find('time').get_text().strip())\n",
    "                    # School URN\n",
    "                    school_info.append(sub_info[report_index].find_all('strong')[1].get_text().strip())\n",
    "                schools_list.append(school_info)\n",
    "            schools_df = pd.DataFrame(schools_list, columns=['school_name','link','address','category','rating','last_report_date','urn'])\n",
    "            # If all schools on the page are in the target district, move to the next page\n",
    "            if schools_df.shape[0] == schools_df[schools_df['address'].str.contains(district)].shape[0]:\n",
    "                try:\n",
    "                    driver.find_element(By.XPATH, \"//a[@class='pagination__next']\").click()\n",
    "                    time.sleep(random.uniform(5,8))\n",
    "                except:\n",
    "                    not_finished = False\n",
    "            else:\n",
    "                not_finished = False\n",
    "        schools_df = pd.DataFrame(schools_list, columns=['school_name','link','address','category','rating','last_report_date','urn'])\n",
    "        schools_df.to_csv(f'{save_folder}/{district}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93021191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This URL has the following selection criteria:\n",
    "# 1) Chosen London district\n",
    "# 2) Radius = 3 miles\n",
    "# 3) Category = 'Education and Training'\n",
    "# 4) Sub-category = 'Primary' (only primary schools)\n",
    "# 5) Status = Open\n",
    "# 6) Query starts at 0\n",
    "# 7) Query should show 100 results\n",
    "url_all = \"https://reports.ofsted.gov.uk/search?q=&location=London+{}%2C+UK&radius=1&radius=3&level_1_types=1&level_2_types=1&latest_report_date_start=&latest_report_date_end=&status%5B%5D=1&start=0&rows=100\"\n",
    "save_folder = 'data/schools'\n",
    "scrape_schools(url_all,save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_schools = []\n",
    "for district in districts:\n",
    "    data_all_schools.append(pd.read_csv(f'data/schools/{district}.csv'))\n",
    "# Concatenate all London schools and drop duplicates\n",
    "# We overscrape - one district query shows queries of other districts as well\n",
    "# Rating and URN have NaNs or might be of multiple types (string, int, float), so we don't consider them in duplication removal\n",
    "# This exclusion does not cause any unique removals \n",
    "data_all_schools = pd.concat(data_all_schools).drop_duplicates(['school_name', 'link', 'address', 'category','last_report_date']).reset_index(drop=True)\n",
    "data_all_schools.to_csv(f'data/all_schools.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77755d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This URL has the same selection criteria as the selection of all schools\n",
    "# Plus, it selects all available religions in 'Religion' filter tab\n",
    "url_religious = \"https://reports.ofsted.gov.uk/search?q=&location=London+{}%2C+UK&radius=1&radius=3&level_1_types=1&level_2_types=1&religion%5B%5D=2&religion%5B%5D=3&religion%5B%5D=4&religion%5B%5D=5&religion%5B%5D=6&religion%5B%5D=7&religion%5B%5D=8&religion%5B%5D=9&religion%5B%5D=10&religion%5B%5D=11&religion%5B%5D=12&religion%5B%5D=13&religion%5B%5D=14&religion%5B%5D=15&religion%5B%5D=16&religion%5B%5D=17&religion%5B%5D=18&religion%5B%5D=19&religion%5B%5D=20&latest_report_date_start=&latest_report_date_end=&status%5B%5D=1&start=0&rows=100\"\n",
    "save_folder_religious = 'data/religious_schools'\n",
    "scrape_schools(url_religious,save_folder_religious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fc69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_religious_schools = []\n",
    "for district in districts:\n",
    "    data_religious_schools.append(pd.read_csv(f'data/religious_schools/{district}.csv'))\n",
    "data_religious_schools = pd.concat(data_religious_schools).drop_duplicates(['school_name', 'link', 'address', 'category','last_report_date']).reset_index(drop=True)\n",
    "data_religious_schools.to_csv(f'data/religious_schools.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add is_religion feature to all schools dataset\n",
    "data_religious_schools['is_religious'] = True \n",
    "data_all_schools = pd.merge(data_all_schools, data_religious_schools[['link','is_religious']], how='left',on=['link'])\n",
    "data_all_schools.loc[data_all_schools['is_religious'].isna(), 'is_religious'] = False\n",
    "# Some schools are not labeled as religious, but contain saints in the names, so change label for them\n",
    "data_all_schools.loc[data_all_schools['school_name'].str.contains('\\s?St '), 'is_religious'] = True\n",
    "data_all_schools.to_csv(f'data/all_schools.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd66ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data/all_schools.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
